{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS\n",
    "num_of_testimages = 100 #small number just to get some images to look at the result\n",
    "mask_size = 9 #Maks size for the masking of the images\n",
    "mask_maxsize = 14 #Max size of the mask\n",
    "mask_minsize = 8 #Min size of the mask\n",
    "ratio_of_dataset = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset and cropping it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist,fashion_mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "import importlib\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "import importlib\n",
    "import expansion\n",
    "importlib.reload(expansion)\n",
    "\n",
    "#(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "(train_X, train_y), (test_X, test_y) = fashion_mnist.load_data()\n",
    "#Takes a ratio of the dataset\n",
    "train_X = train_X[0:int(ratio_of_dataset*len(train_X))]\n",
    "test_X = test_X[0:int(ratio_of_dataset*len(test_X))]\n",
    "#Normalize values 0 to 1\n",
    "train_X = train_X/255\n",
    "test_X = test_X/255\n",
    "\n",
    "np.random.shuffle(test_X) #Get randomness in the test images later\n",
    "\n",
    "train_X = np.expand_dims(train_X, axis=-1)  # Shape: (60000, 28, 28, 1)\n",
    "valid_X = np.expand_dims(test_X[num_of_testimages:10000], axis=-1) # All the images for validation\n",
    "test_X = np.expand_dims(test_X[0:num_of_testimages], axis=-1)    # The test images, to visualize later\n",
    "\n",
    "print('X_train: ' + str(train_X.shape))\n",
    "print('valid_X:  '  + str(valid_X.shape))\n",
    "print('test_X '  + str(test_X.shape))\n",
    "\n",
    "expansion.image_grid(test_X, name=\"Images before crop\")\n",
    "\n",
    "#Mask with center mask with fixed size\n",
    "#train_X_crop = center_mask(train_X, mask_size)\n",
    "#valid_X_crop = center_mask(valid_X, mask_size)\n",
    "#test_X_crop = center_mask(test_X, mask_size)\n",
    "\n",
    "#Mask with random mask position and size\n",
    "train_X_crop, train_mask = expansion.random_mask(train_X, mask_minsize, mask_maxsize)\n",
    "valid_X_crop, valid_mask = expansion.random_mask(valid_X, mask_minsize, mask_maxsize)\n",
    "test_X_crop, test_mask = expansion.random_mask(test_X, mask_minsize, mask_maxsize)\n",
    "\n",
    "expansion.image_grid(test_X_crop, name=\"After crop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETRAR FÖR TRÄNING\n",
    "runs = 4 #Number of runs to calculate the avarage over    5\n",
    "epochs = 40 #Number of epoches for all the models, so they use same number of epochs, we have early stopping if this is too much   30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSIM_results = []\n",
    "mse_results = []\n",
    "for n in range(runs):\n",
    "  K.clear_session()\n",
    "\n",
    "  batch_size = 128\n",
    "\n",
    "  image_input = layers.Input(shape=train_X_crop.shape[1:], name=\"image_input\")\n",
    "\n",
    "  # Encoder\n",
    "  conv1 = layers.Conv2D(8, (3, 3), activation='relu', padding='same',strides=(2,2))(image_input)\n",
    "  conv1 = layers.BatchNormalization()(conv1)\n",
    "\n",
    "  conv2 = layers.Conv2D(16, (3, 3), activation='relu', padding='same', strides=(2,2))(conv1)\n",
    "  conv2 = layers.BatchNormalization()(conv2)\n",
    "\n",
    "  # Bottleneck\n",
    "  conv3 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "  conv3 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv3)\n",
    "\n",
    "  # Decoder\n",
    "  up1 = layers.UpSampling2D((2, 2))(conv3)\n",
    "  conv4 = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(up1)\n",
    "\n",
    "  up2 = layers.UpSampling2D((2, 2))(conv4)\n",
    "  conv5 = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(up2)\n",
    "\n",
    "  # Output layer\n",
    "  outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(conv5) #Sigmoid for [0, 1] pixel values\n",
    "\n",
    "  # Model\n",
    "  model = keras.models.Model(inputs=image_input, outputs=outputs)\n",
    "  model.summary()\n",
    "\n",
    "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['mse'])\n",
    "\n",
    "  early_stopping = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n",
    "\n",
    "  # Train the model\n",
    "  history = model.fit(\n",
    "      train_X_crop,\n",
    "      train_X,\n",
    "      epochs=epochs,\n",
    "      batch_size=batch_size,\n",
    "      validation_data=(valid_X_crop, valid_X),\n",
    "      callbacks=[early_stopping]\n",
    "      )\n",
    "\n",
    "  # Predict and visualize\n",
    "  predicted_images = model.predict(test_X_crop)\n",
    "  # Calculate SSIM\n",
    "  ssim_score = expansion.calculate_ssim(test_X, predicted_images)\n",
    "  print(\"SSIM Score:\", ssim_score)\n",
    "  SSIM_results.append(ssim_score)\n",
    "\n",
    "  # Calculate MSE\n",
    "  mse_test_images = np.mean((test_X - predicted_images) ** 2)\n",
    "  print(\"MSE Score:\", mse_test_images)\n",
    "  mse_results.append(mse_test_images)\n",
    "\n",
    "  expansion.image_grid(test_X_crop, name=\"Cropped images\")\n",
    "  expansion.image_grid(test_X, name=\"Original images\")\n",
    "  expansion.image_grid(predicted_images, name=\"Predicted images\")\n",
    "\n",
    "print(SSIM_results)\n",
    "print(mse_results)\n",
    "\n",
    "print(\"Average SSIM Score over \",runs,\" runs: \", np.mean(SSIM_results))\n",
    "print(\"Average MSE over \",runs,\" runs: \", np.mean(mse_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improved autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSIM_results = []\n",
    "mse_results = []\n",
    "for n in range(runs):\n",
    "  K.clear_session()\n",
    "\n",
    "  batch_size = 128\n",
    "\n",
    "  image_input = layers.Input(shape=train_X_crop.shape[1:], name=\"image_input\")\n",
    "  mask_input = layers.Input(shape=train_mask.shape[1:], name=\"mask_input\")\n",
    "  combined_input = layers.concatenate([image_input, mask_input], axis=-1)\n",
    "\n",
    "  # Encoder\n",
    "  conv1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(combined_input)\n",
    "  conv1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same',strides=(2,2))(conv1)\n",
    "  conv1 = layers.BatchNormalization()(conv1)\n",
    "\n",
    "  conv2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv1)\n",
    "  conv2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same', strides=(2,2))(conv2)\n",
    "  conv2 = layers.BatchNormalization()(conv2)\n",
    "\n",
    "  # Bottleneck\n",
    "  conv3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(conv2)\n",
    "  conv3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n",
    "\n",
    "  # Decoder\n",
    "  up1 = layers.UpSampling2D((2, 2))(conv3)\n",
    "  conv4 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(up1)\n",
    "  conv4 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv4)\n",
    "\n",
    "\n",
    "  up2 = layers.UpSampling2D((2, 2))(conv4)\n",
    "  conv5 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(up2)\n",
    "  conv5 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "  # Output layer\n",
    "  outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(conv5)  # Sigmoid for [0, 1] pixel values\n",
    "\n",
    "  # Model\n",
    "  model = keras.models.Model(inputs=[image_input, mask_input], outputs=outputs)\n",
    "  model.summary()\n",
    "\n",
    "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['mse'])\n",
    "\n",
    "  early_stopping = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n",
    "\n",
    "  # Train the model\n",
    "  history = model.fit(\n",
    "      [train_X_crop, train_mask],\n",
    "      train_X,\n",
    "      epochs=epochs,\n",
    "      batch_size=batch_size,\n",
    "      validation_data=([valid_X_crop, valid_mask], valid_X),\n",
    "      callbacks=[early_stopping]\n",
    "      )\n",
    "\n",
    "  # Predict and visualize\n",
    "  predicted_images = model.predict([test_X_crop, test_mask])\n",
    "\n",
    "  # Calculate SSIM\n",
    "  ssim_score = expansion.calculate_ssim(test_X, predicted_images)\n",
    "  print(\"SSIM Score:\", ssim_score)\n",
    "  SSIM_results.append(ssim_score)\n",
    "\n",
    "  # Calculate MSE\n",
    "  mse_test_images = np.mean((test_X - predicted_images) ** 2)\n",
    "  print(\"MSE Score:\", mse_test_images)\n",
    "  mse_results.append(mse_test_images)\n",
    "\n",
    "  expansion.image_grid(test_X_crop, name=\"Cropped images\")\n",
    "  expansion.image_grid(test_X, name=\"Original images\")\n",
    "  expansion.image_grid(predicted_images, name=\"Predicted images\")\n",
    "\n",
    "print(\"Average SSIM Score over \",runs,\" runs: \", np.mean(SSIM_results))\n",
    "print(\"Average MSE over \",runs,\" runs: \", np.mean(mse_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Net autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSIM_results = []\n",
    "mse_results = []\n",
    "for n in range(runs):\n",
    "  K.clear_session()\n",
    "\n",
    "  batch_size = 128\n",
    "\n",
    "  image_input = layers.Input(shape=train_X_crop.shape[1:], name=\"image_input\")\n",
    "  mask_input = layers.Input(shape=train_mask.shape[1:], name=\"mask_input\")\n",
    "\n",
    "  combined_input = layers.concatenate([image_input, mask_input], axis=-1)\n",
    "\n",
    "  # Encoder\n",
    "  conv1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(combined_input)\n",
    "  pool1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same',strides=(2,2))(conv1)\n",
    "  pool1 = layers.BatchNormalization()(pool1)\n",
    "\n",
    "  conv2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
    "  pool2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same', strides=(2,2))(conv2)\n",
    "  pool2 = layers.BatchNormalization()(pool2)\n",
    "\n",
    "  # Bottleneck\n",
    "  conv3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
    "  conv3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n",
    "\n",
    "  # Decoder\n",
    "  up1 = layers.UpSampling2D((2, 2))(conv3)\n",
    "  concat1 = layers.concatenate([up1, conv2], axis=-1)  # Skip connection\n",
    "  conv4 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(concat1)\n",
    "  conv4 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv4)\n",
    "\n",
    "\n",
    "  up2 = layers.UpSampling2D((2, 2))(conv4)\n",
    "  concat2 = layers.concatenate([up2, conv1], axis=-1)  # Skip connection\n",
    "  conv5 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(concat2)\n",
    "  conv5 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "\n",
    "  # Output layer\n",
    "  outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(conv5)  # Sigmoid for [0, 1] pixel values\n",
    "\n",
    "  # Model\n",
    "  model = keras.models.Model(inputs=[image_input, mask_input], outputs=outputs)\n",
    "  model.summary()\n",
    "\n",
    "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['mse'])\n",
    "\n",
    "  early_stopping = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n",
    "\n",
    "  # Train the model\n",
    "  history = model.fit(\n",
    "      [train_X_crop, train_mask],\n",
    "      train_X,\n",
    "      epochs=epochs,\n",
    "      batch_size=batch_size,\n",
    "      validation_data=([valid_X_crop, valid_mask], valid_X),\n",
    "      callbacks=[early_stopping]\n",
    "      )\n",
    "\n",
    "\n",
    "  # Predict and visualize\n",
    "  predicted_images = model.predict([test_X_crop, test_mask])\n",
    "\n",
    "  # Calculate SSIM\n",
    "  ssim_score = expansion.calculate_ssim(test_X, predicted_images)\n",
    "  print(\"SSIM Score:\", ssim_score)\n",
    "  SSIM_results.append(ssim_score)\n",
    "\n",
    "  # Calculate MSE\n",
    "  mse_test_images = np.mean((test_X - predicted_images) ** 2)\n",
    "  print(\"MSE Score:\", mse_test_images)\n",
    "  mse_results.append(mse_test_images)\n",
    "\n",
    "  expansion.image_grid(test_X_crop, name=\"Cropped images\")\n",
    "  expansion.image_grid(test_X, name=\"Original images\")\n",
    "  expansion.image_grid(predicted_images, name=\"Predicted images\")\n",
    "\n",
    "print(\"Average SSIM Score over \",runs,\" runs: \", np.mean(SSIM_results))\n",
    "print(\"Average MSE over \",runs,\" runs: \", np.mean(mse_results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
